Index: simul.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from setup import pd, rn, np, Path, SeqIO, opxl, mp, partial\r\n\r\n#load_protease uses the protease param to load an excel sheet containing two sheets, with one counting the number of experimentally observed cleavages, and the other containing the total number of potential cleavage sites observed, the function then returns the number of cleavages divided by the number of total occurences as a probability table\r\ndef load_protease(protease='pepsin'):\r\n    protease_file = Path('data') / protease / f'{protease}.xlsx'\r\n\r\n    cleavage_table = pd.read_excel(protease_file, sheet_name=['cleavages', 'totals'], index_col=0)\r\n\r\n    cleavages = cleavage_table['cleavages']\r\n    totals = cleavage_table['totals']\r\n\r\n    cleavages = cleavages.astype(float)\r\n    totals = totals.astype(float)\r\n\r\n    prob_table = cleavages.div(totals)\r\n\r\n    return prob_table\r\n\r\n\r\n\r\n#digest reads in a fasta file, loads the probability table for cleavages between residues specific to the protease param, and then iterates through the sequence and uses the probabilities from the table to determine where \"cleavages\" happen, these fragments are added to the list, and the entire sequence is digested n times (given by param n, default 1000) and the list containing all the fragments is returned\r\ndef digest(fasta_file, n=1000, protease='pepsin'):\r\n\r\n    with open(fasta_file, 'r') as file:\r\n        protein_seq = SeqIO.read(file, 'fasta').seq\r\n\r\n    cleavage_table = load_protease(protease)\r\n\r\n    fragments = []\r\n    for i in range(n):\r\n        prev = 0\r\n        for j in range(len(protein_seq) - 2):\r\n            p1 = protein_seq[j]\r\n            p1p = protein_seq[j+1]\r\n            prob = cleavage_table.loc[p1, p1p]\r\n            if rn.random() < prob and j + 1 - prev >= 4 and rn.random() < 0.5:\r\n                fragments.append(protein_seq[prev:j+1])\r\n                prev = j + 1\r\n\r\n    return fragments
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/simul.py b/simul.py
--- a/simul.py	(revision 2da0240daa926cd5cf9665495b08d93f8c5cb5d1)
+++ b/simul.py	(date 1714592282839)
@@ -2,7 +2,7 @@
 
 #load_protease uses the protease param to load an excel sheet containing two sheets, with one counting the number of experimentally observed cleavages, and the other containing the total number of potential cleavage sites observed, the function then returns the number of cleavages divided by the number of total occurences as a probability table
 def load_protease(protease='pepsin'):
-    protease_file = Path('data') / protease / f'{protease}.xlsx'
+    protease_file = Path('utility/data') / protease / f'{protease}.xlsx'
 
     cleavage_table = pd.read_excel(protease_file, sheet_name=['cleavages', 'totals'], index_col=0)
 
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from setup import plt, sns\r\nimport simul, exper\r\n\r\nfasta_file = \"S100b.fasta\"\r\nfragments = simul.digest(fasta_file, n=1000)\r\n\r\n# Print the distribution of the first two letters of each sequence\r\nfragment_lengths = [len(fragment) for fragment in fragments]\r\n\r\n\r\nfragment_counts = {}\r\nfor fragment in fragments:\r\n    fragment_counts[fragment] = fragment_counts.get(fragment, 0) + 1\r\n\r\n# Sort the dictionary by values (frequencies) in descending order\r\nsorted_fragment_counts = dict(sorted(fragment_counts.items(), key=lambda item: item[1], reverse=True))\r\n\r\n# Get the top 100 most common fragments\r\ntop_100_fragments = list(sorted_fragment_counts.keys())[:100]\r\n\r\n# Print the list of top 100 fragments\r\nprint(\"Top 100 fragments:\")\r\nfor fragment in top_100_fragments:\r\n    print(fragment)\r\n\r\n# plt.subplot(2, 1, 1)\r\n# sns.violinplot(y=fragment_lengths, color='skyblue')\r\n#\r\n# # Add labels and title\r\n# plt.xlabel('Density')\r\n# plt.ylabel('Fragment Length')\r\n# plt.title('Distribution of Fragment Lengths')\r\n#\r\n# # Show plot\r\n# plt.show(block=True)\r\n#\r\n#\r\n# filtered_fragments = [fragment for fragment in fragments if len(fragment) > 1]\r\n#\r\n# # Extract the first two letters of each sequence\r\n# first_two_letters = [str(fragment)[:2] for fragment in filtered_fragments]\r\n#\r\n# # Count the frequency of each pair of letters\r\n# letter_counts = {}\r\n# for letters in first_two_letters:\r\n#     letter_counts[letters] = letter_counts.get(letters, 0) + 1\r\n#\r\n# # Sort the dictionary by values (frequencies) in descending order\r\n# sorted_letter_counts = dict(sorted(letter_counts.items(), key=lambda item: item[1], reverse=True))\r\n#\r\n# # Get the top 25 most common two-letter starts\r\n# top_10_starts = list(sorted_letter_counts.items())[:10]\r\n#\r\n# # Extract letters and frequencies for the top 25 starts\r\n# letters = [start[0] for start in top_10_starts]\r\n# frequencies = [start[1] for start in top_10_starts]\r\n#\r\n# # Determine the number of bars\r\n# num_bars = len(letters)\r\n#\r\n# # Set the width of each bar\r\n# bar_width = 0.8\r\n#\r\n#\r\n# # Create the bar plot (histogram) with adjusted bar width\r\n# plt.subplot(2, 1, 2)\r\n# plt.bar(letters, frequencies, width=bar_width, color='skyblue')\r\n#\r\n# # Add labels and title\r\n# plt.xlabel('First Two Letters')\r\n# plt.ylabel('Frequency')\r\n# plt.title('Frequency of First Two Letters in Sequences (Top 10)')\r\n#\r\n# # Rotate x-axis labels for better visibility if needed\r\n# plt.xticks(rotation=45)\r\n#\r\n# # Show plot\r\n# plt.show(block=True)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	(revision 2da0240daa926cd5cf9665495b08d93f8c5cb5d1)
+++ b/main.py	(date 1714592387345)
@@ -1,78 +1,18 @@
 from setup import plt, sns
 import simul, exper
 
-fasta_file = "S100b.fasta"
+fasta_file = "utility/testing/S100b.fasta"
 fragments = simul.digest(fasta_file, n=1000)
 
-# Print the distribution of the first two letters of each sequence
-fragment_lengths = [len(fragment) for fragment in fragments]
-
 
 fragment_counts = {}
 for fragment in fragments:
     fragment_counts[fragment] = fragment_counts.get(fragment, 0) + 1
 
-# Sort the dictionary by values (frequencies) in descending order
 sorted_fragment_counts = dict(sorted(fragment_counts.items(), key=lambda item: item[1], reverse=True))
 
-# Get the top 100 most common fragments
 top_100_fragments = list(sorted_fragment_counts.keys())[:100]
 
-# Print the list of top 100 fragments
 print("Top 100 fragments:")
 for fragment in top_100_fragments:
     print(fragment)
-
-# plt.subplot(2, 1, 1)
-# sns.violinplot(y=fragment_lengths, color='skyblue')
-#
-# # Add labels and title
-# plt.xlabel('Density')
-# plt.ylabel('Fragment Length')
-# plt.title('Distribution of Fragment Lengths')
-#
-# # Show plot
-# plt.show(block=True)
-#
-#
-# filtered_fragments = [fragment for fragment in fragments if len(fragment) > 1]
-#
-# # Extract the first two letters of each sequence
-# first_two_letters = [str(fragment)[:2] for fragment in filtered_fragments]
-#
-# # Count the frequency of each pair of letters
-# letter_counts = {}
-# for letters in first_two_letters:
-#     letter_counts[letters] = letter_counts.get(letters, 0) + 1
-#
-# # Sort the dictionary by values (frequencies) in descending order
-# sorted_letter_counts = dict(sorted(letter_counts.items(), key=lambda item: item[1], reverse=True))
-#
-# # Get the top 25 most common two-letter starts
-# top_10_starts = list(sorted_letter_counts.items())[:10]
-#
-# # Extract letters and frequencies for the top 25 starts
-# letters = [start[0] for start in top_10_starts]
-# frequencies = [start[1] for start in top_10_starts]
-#
-# # Determine the number of bars
-# num_bars = len(letters)
-#
-# # Set the width of each bar
-# bar_width = 0.8
-#
-#
-# # Create the bar plot (histogram) with adjusted bar width
-# plt.subplot(2, 1, 2)
-# plt.bar(letters, frequencies, width=bar_width, color='skyblue')
-#
-# # Add labels and title
-# plt.xlabel('First Two Letters')
-# plt.ylabel('Frequency')
-# plt.title('Frequency of First Two Letters in Sequences (Top 10)')
-#
-# # Rotate x-axis labels for better visibility if needed
-# plt.xticks(rotation=45)
-#
-# # Show plot
-# plt.show(block=True)
\ No newline at end of file
Index: .idea/vcs.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"VcsDirectoryMappings\">\r\n    <mapping directory=\"$PROJECT_DIR$\" vcs=\"\" />\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
--- a/.idea/vcs.xml	(revision 2da0240daa926cd5cf9665495b08d93f8c5cb5d1)
+++ b/.idea/vcs.xml	(date 1714591814759)
@@ -1,6 +1,6 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="VcsDirectoryMappings">
-    <mapping directory="$PROJECT_DIR$" vcs="" />
+    <mapping directory="$PROJECT_DIR$" vcs="Git" />
   </component>
 </project>
\ No newline at end of file
